\title{Risk functions for multivariate prediction}
\author{Charles Zheng and Yuval Benjamini}
\date{\today}

\documentclass[12pt]{article} 

% packages with special commands
\usepackage{amssymb, amsmath}
\usepackage{epsfig}
\usepackage{array}
\usepackage{ifthen}
\usepackage{color}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{mathtools}
\usepackage{csquotes}
\definecolor{grey}{rgb}{0.5,0.5,0.5}

\begin{document}
\maketitle

\newcommand{\tr}{\text{tr}}
\newcommand{\E}{\textbf{E}}
\newcommand{\diag}{\text{diag}}
\newcommand{\argmax}{\text{argmax}}
\newcommand{\Cov}{\text{Cov}}
\newcommand{\Var}{\text{Var}}
\newcommand{\argmin}{\text{argmin}}
\newcommand{\Vol}{\text{Vol}}
\newcommand{\comm}[1]{}

Broadly speaking, the goal of \emph{supervised learning} is to learn
the conditional distribution of the response $Y$ conditional on
predictors $x$.  Here we are interested in the case of where both the
predictors $x \in \mathbb{R}^p$ and response $Y \in \mathbb{R}^q$ are
high-dimensional.  Later we will be particularly interested in the
special case
$$
Y|x \sim N(B^T x, \Sigma)
$$
where the unknown parameters are $B$, a $p \times q$ coefficient
matrix and $\Sigma$, a $q \times q$ covariance matrix.

But let us return now to the general case.  Suppose that in truth,
$Y|x$ has a distribution $F_x$.  Based on training data, we estimate
some map $\hat{F}: x \mapsto \hat{F}_x$, where $\hat{F}_x$ is an
estimate of the distribution $Y|x$.  Is $\hat{F}_x$ a good estimate of
the truth, $F_x$? Well, it depends on what our ultimate goal is.  If
our goal is simply to produce a prediction $\hat{Y}$ that minimizes
the squared error loss with the observed $Y$, then we should choose
$\hat{Y} = \E_{\hat{F}_x} Y$, and hence the risk function we should
use to evaluate our procedure is the usual squared-error prediction
risk,
\[
\text{risk}_{pred}(\hat{F}_x) = \E[||Y - \hat{Y}||^2] = \E[||Y - \E_{\hat{F}_x} Y||^2].
\]
Supposing the covariate is also a random variable, then we want to
average the above risk function over the random distribution of $X$,
defining
\[
\text{Risk}_{pred}(\hat{F}) = \E[\text{risk}_{pred}(\hat{F}_x)|X = x].
\]

Yet, $\text{risk}_{pred}$ is not the only risk function one could use.
Assuming that $F_x$ has a density $f_x$ relative to some measure $\mu$, one
could define the Kullback-Liebler risk as
\[
\text{risk}_{KL}(\hat{F}_x) = -\E[\log \hat{f}_x(Y)]
\]
Unlike $\text{risk}_{pred}$, the Kullback-Liebler loss requires us to
get a good estimate of the whole distribution, not just its mean.  And
as before, if $X$ is random, we can define
$\text{Risk}_{KL}(\hat{F})$ similarly to before.

It could be expected that using different risk functions leads to
different theoretical approaches and procedures.  While
$\text{risk}_{pred}$ is one of the simpler cases, it already lends
itself to sophisticated approaches involving simultaneous estimation
of $B$ and $\Sigma$: see, for instance Witten and Tibshirani (2008).
Presumably, minimizing $\text{risk}_{KL}$ would have to involve even
more complicated procedures, if the problem is even tractable at the
moment.  Yet, researchers are often interested in knowing more than
the conditional mean: hence it would be interesting to look at risk
functions which are somewhat more involved than $\text{risk}_{pred}$,
but which may be easier from both a theoretical and practical
perspective than $\text{risk}_{KL}$.  Note that both
$\text{risk}_{pred}$ and $\text{risk}_{KL}$ have the property that
they are minimized by the true value $F_x$:
\[
\min \text{risk}(\hat{F}_x) = \text{risk}(F_x)
\]
We might call a risk function ``unbiased'' if it has this property:
not to be confused with the unbiasedness of the estimators!  A
unbiased risk function might still be minimized by a biased estimator.
On the other hand, it is hard to imagine why one would ever want to study a
biased risk function.

Stopping short of estimating the conditional distribution, one might
evaluate the first two moments of $\hat{F}_x$, by using
\[
\text{risk}_{\Sigma} = \E[(Y - \hat{Y})^T \hat{\Sigma}^{-1} (Y - \hat{Y})] + \log \det \hat{\Sigma}
\]
where $\hat{Y}$ is the mean of $\hat{F}_x$ and $\hat{\Sigma}$ is the
covariance of $\hat{F}_x$. It is easy to show that
$\text{risk}_{\Sigma}$ is unbiased: first note that fixing
$\hat{\Sigma}$, the risk is minimized by $\hat{Y} = \E[Y|x]$; using
this choice of $\hat{Y}$, the risk simplifies to
$\E\tr(\Sigma\hat{\Sigma}^{-1}) + \log\det\hat{\Sigma}$, which is
stationary at $\hat{\Sigma} = \Sigma$.

Hence, we have thus far listed three ways to evaluate the quality of
map $\hat{F}$ based on observed $Y$: prediction risk, KL risk, and 
covariance risk.
It is worth noting that prediction risk and covariance risk are
equivalent to $\text{risk}_{KL}$ for the gaussian model with identity
covariance and unknown covariance, respectively.

However, there are yet more ways to evaluate the quality of the
estimated map $\hat{F}$.  Letting $(X^*, Y^*)$ be a new covariate and
response, I could give you the response $Y^*$, and ask you to predict the
covariate $X^*$.  Your goal would be to minimize the squared error risk for $X^*$:
\[
\text{risk} = \E[||X^* - \hat{X}||^2]
\]
Supposing you knew the distribution of $X^*$ in advance, $p(x)$,
you should choose
\[
\hat{X} = \frac{\int x \hat{f}_x(Y^*) p(x) dx}{\int \hat{f}_x(Y^*) p(x) dx}.
\]
In the context of neuroscience, the problem of predicting $x$ given
$y$, where $x$ represents a stimulus and $y$ a neuronal response, is
known as \emph{stimulus reconstruction}.  Hence we define
\[
\text{Risk}_{recon}(\hat{F}) = \E[||X^* - \hat{X}||^2]
\]
where $\hat{X}$ is defined as $\frac{\int x \hat{f}_x(Y^*) p(x)
dx}{\int \hat{f}_x(Y^*) p(x) dx}$.

But now suppose that $X^*$ is initially sampled from a finite sample
from $p(x)$: $x_1,\hdots, x_\ell$.  If I gave you $Y^*$ and also the
initial \emph{candidate set} $x_1,\hdots, x_\ell$, then there is a
nonzero probability of being able to predict $X^*$ exactly, and one uses
0-1 loss to evaluate the \emph{misclassification risk},
\[
\text{risk} = \Pr[X^* \neq \hat{X}]
\]
The advatantage here is that besides the choice of $x_1,\hdots,
x_\ell$ (which can be randomized), the misclassification risk is in
some sense less arbitrary than the reconstruction risk as it does not
depend on the scaling of $x$.  Under this risk, you ought to choose
$X^*$ by
\[
\hat{X} = \argmax_{x_1,\hdots, x_\ell} \hat{f}_x(y)
\]
In the context of neuroscience, this classification task is known as \emph{identification.}
With $\hat{X}$ defined as above, we thus define
\[
\text{Risk}_{ident, \ell}(\hat{F}) = \E_{x_1,\hdots, x_\ell \sim p(x)} \Pr[X^* \neq \hat{X}]
\]
making it clear that the risk is averaged over the random draws of $x_1,\hdots, x_\ell$.

Finally, we have an expanded list of evaluation criteria:
\begin{enumerate}
\item Prediction risk $\text{Risk}_{pred}$
\item KL risk $\text{Risk}_{KL}$
\item Covariance risk $\text{Risk}_{\Sigma}$
\item Reconstruction risk $\text{Risk}_{recon}$
\item Identification risk $\text{Risk}_{ident}$
\end{enumerate}

How does the choice of risk function affect the difficulty of the
resulting supervised learning task?  Can the same approaches be used
for multiple problems in the list, or does each choice of risk
function demand a particular set of approaches?

In the case of prediction risk, one need only estimate the
conditional mean function $\E[Y|x]$; for covariance risk, one needs to
estimate the conditional mean and covariance; for reconstruction and
identification, one might achieve best results by modelling the
conditional distribution $F_x$, but it may also be adequate to simply
use a Gaussian model for $F_x$ in which case only a conditional mean
and covariance need to be estimated.  For KL risk, a Gaussian model
might be extremely suboptimal under misspecification, and full
density-estimation approach may be warranted.

In any case, a first practical step would be to look at these problems
in the Gaussian linear model.

\end{document}



