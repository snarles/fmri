#TALK ABSTRACT

"How many neurons does it take to classify a lightbulb?"

The brain is a stunning example of a complex system built from a vast network of relatively simple individual components.  These components, neurons, are relatively well-understood as chemical and electrical input-output systems, but neuroscientists face the challenge of explaining how these elements interact to build up a functioning brain.  For instance, how does the signalling behavior of a group of neurons combine to convey high-dimensional information, such as visual stimuli?  Information theory provides a promising set of tools for characterizing how individual neurons work together to build up complex signals, by providing a calculus of information for quantifying how the information content of a neural ensemble decomposes into the information contained in each neuron and the information carried by their interactions.  However, since the key quantities of information theory were originally developed by Shannon to describe man-made systems, we face a new challenge of inferring those quantities from data.  In this work, I explore the possibility of using machine learning as a means of inferring mutual information between complex stimuli and large ensembles of brain activation signals.  While the close connection between misclassification rate and mutual information is apparent from Shannon's original work, the connection becomes complicated in experimental studies where limited sample sizes prevent recovery of the optimal classification rule.  We study a Gaussian signal model in an attempt to disentangle the finite sample size effect from the relationship between mutual information and classification rate; our theoretical results are applied to simulations involving more realistic non-Gaussian models.
