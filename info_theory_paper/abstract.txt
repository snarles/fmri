#TALK ABSTRACT

"How many neurons does it take to classify a lightbulb?"

The brain is a stunning example of a complex system built from a vast network of relatively 
simple individual components.  These components, neurons, are relatively well-understood as 
chemical and electrical input-output systems, but neuroscientists face the formidable challenge
of explaining how these elements interact to build up a functioning brain.  For instance, how
does the signalling behavior of a group of neurons combine to convey high-dimensional information, 
such as visual stimuli?  One of the key theoretical tools used in the field is information theory,
which provides a calculus of information for describing how information can be added and subtracted
in systems of neurons.  However, since the key quantities of information theory were originally 
developed by Shannon to describe man-made systems, it becomes a new challenge to reverse the 
usual paradigm of information theory and infer information-theoretic quantities from naturally
occurring neural systems.  In this work, I explore the possibility of using machine learning as 
a means of inferring mutual information between complex stimuli and large ensembles of brain 
activation signals.  While the close connection between misclassification rate and mutual 
information is apparent from Shannon's original work, the connection becomes complicated in 
experimental studies where limited sample sizes prevent recovery of the optimal classification 
rule.  We study a Gaussian signal model in an attempt to disentangle the finite sample size effect 
from the relationship between mutual information and classification rate; then we compare
our theoretical results to simulations involving more realistic non-Gaussian models.
