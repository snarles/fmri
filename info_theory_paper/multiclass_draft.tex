\title{Extrapolating Multi-class classification curves}
\author{Charles Zheng and Yuval Benjamini}
\date{\today}

\documentclass[12pt]{article} 

% packages with special commands
\usepackage{amssymb, amsmath}
\usepackage{epsfig}
\usepackage{array}
\usepackage{ifthen}
\usepackage{color}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{mathtools}
\usepackage{csquotes}
\definecolor{grey}{rgb}{0.5,0.5,0.5}

\begin{document}
\maketitle

\newcommand{\tr}{\text{tr}}
\newcommand{\E}{\textbf{E}}
\newcommand{\diag}{\text{diag}}
\newcommand{\argmax}{\text{argmax}}
\newcommand{\Cov}{\text{Cov}}
\newcommand{\Var}{\text{Var}}
\newcommand{\argmin}{\text{argmin}}
\newcommand{\Vol}{\text{Vol}}
\newcommand{\comm}[1]{}

\section{Introduction}

Object recognition, face recognition (or more generally person recognition) and language are a few of
the cognitive building blocks which are fundamental to human cognition, and which can be understood as 
examples of generalized classification tasks.  Fundamentally, humans learn to recognize objects,
persons, or linguistic entities and learn equivalence relationships between perceived objects, words, 
or individuals.  A child will encounter their neighbor's dog for the first time, and at a later date,
encounter the same dog in a different time or place.  But they will recognize that the dog is the same dog
they met before.

Machine classification can be employed to mimic this power of recognition.
A robot equipped with a camera can algorithmically segment its input image into objects,
and to learn to recognize unique objects and people which regularly appear in its environment.
A general approach to implement such a recognition ability starts by employing some
parametric featurization of the object to be identified.  For example, for the task of
face recognition, one might define features such as the proportions between the eyes and the relative position
and size of the nose.  Such features can be estimated from the video input,
and while the estimated features might vary slightly depending on the configuration of the object
(e.g. posture of the body, emotional expression of the face, opening/closing of the mouth)
and while some features might be unobserved because of occlusion,
the regularity of the the identified features can still be used as a basis for recognition.
In the simplest case, a feature vector can be extracted from a given object from the input data,
and this feature vector can be evaluated against a library of learned models
for the distribution of the feature vector for various objects.
In other words, given a method for extracting objects from input and producing feature vectors
for those objects, one can employ multi-class classification to identify the object corresponding to the 
feature vector.  In our discussion thus far, we neglected to mention how to learn
object categories for novel objects, but this falls outside of the scope of the paper.

A limitation to such recognition systems, whether they be natural or artificial,
is that the performance of the system (in terms of correct classification)
can degrade if there are too many categories.
A face recognition algorithm can have very high success rate if it only needs
to distinguish between 100 different faces, but its identifications may be less reliable
when it needs to distinguish between 10000 different faces.
In humans, it is known that repetition learning is hampered when there are
too many similar concepts to be learned.

The tradeoff between performance and the number of categories can be summarized
by a \emph{classification curve} while plots the accuracy versus the number of categories.
An interesting question is whether it is possible to \emph{extrapolate} a classification curve:
i.e. given the performance with up to $N$ classes, can one predict the performance
when the number of classes is increased to $2N$?

In the most general setting, only fairly trivial worst-case guarantees are possible.
Suppose a system has an accuracy of $p$ given the $N$-class problem,
i.e., given a random feature vector, the system correctly identifies the class with probability $p$.
Then, what can we say about the performance when $N$ additional classes are added?
In a very bad (not necessarily the `worst') case, the $N$ additional classes are identical copies
or the original $N$ classes, except we still consider it an error if a feature vector from one of the new classes
is identified as coming from the corresponding class in the original set, or vice versa.
In that case, a reasonable system would be the original system, but adding a coin flip to choose
between the original classes or the copied new classes, and the resulting accuracy would
be reduced from $p$ to $p/2$ due to the coin flip.  In general, we can state that when going from $N$
classes to $kN$ classes, the Bayes accuracy might be as low as $p/k$.

We can obtain more meaningful bounds if we are willing to assume more structure to the problem.
In many applications, such as face recognition or word recognition, a reasonable model
is to assume that there exists an infinite population of classes, and that given a classification problem
with $N$ classes, that those $N$ classes were drawn i.i.d. from this infinite population.
This is `random classification model' is the setting we consider in this paper.

\section{Setup}

Let $\mathcal{X}$ be a space of objects to be recognized, and let the objects be uniquely parameterized
by a real vector $x \in \mathcal{X}$.  
Let $y \in \mathcal{Y}$ be a possible feature vector for an object in $\mathcal{X}$.
Let $p(x)$ be a distribution of random objects, and let a conditional feature vector distribution 
$p(y|x)$ be defined for every $x \in \mathcal{X}$.

The $k$-class random classification task is defined as follows.
First, the $k$ classes are drawn iid from $\mathcal{X}$, represented by vectors $x_1,\hdots, x_k$.
One obtains training data consisting of independent 
$(x, y)$ pairs, where $x$ is equal to one of $x_1,\hdots, x_k$
and $y$ is drawn from $p(y|x)$.
Based on the training data, one constructs a classification rule $f$ which maps a feature vector
to one of $\{x_1,\hdots, x_k\}$.
The accuracy of the classification rule is
\[
\Pr[f(y) = x|x \sim \text{Unif}\{x_1,\hdots, x_k\}].
\]
The accuracy depends on what model is used to learn the classification rule.
Hence, discussing the properties of the accuracy for finite sample sizes and specific
classification rules is an immense task, falling outside of the scope of the paper.
However, it is vastly easier to work with the accuracy of the \emph{Bayes rule},
which is the optimal classification rule.
This is because the Bayes rule $f^*$ can be written explicitly as
\[
f^*(y) = \argmax_{x_1,\hdots, x_k} p(y|x).
\]
Since there exist consistent estimators of the Bayes rule (under mild regularity conditions,)
the theory we develop for the accuracy of the Bayes rule can be viewed as a large-sample approximation
of the original problem.
Henceforth we work with the accuracy of the Bayes rule for the $k$-class classification problem, $P_k$,
where
\[
P_k = \Pr[\argmax_{x_1,\hdots, x_k} p(y|x) = x | x \sim \text{Unif}\{x_1,\hdots, x_k\}].
\]
Notice that $P_k$ is a random variable, since it varies depending on the sampling of $x_1,\hdots, x_k$.
Hence the average Bayes accuracy $p_k$ is defined as
\[
p_k = E[P_k]
\]
where the expectation is taken over the sampling distribution of $x_1,\hdots, x_k$.


\end{document}



