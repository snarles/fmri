% Chapter 1

\chapter{Introduction} % Main chapter title

\label{Chapter1} % For referencing the chapter elsewhere, use \ref{Chapter1} 

%----------------------------------------------------------------------------------------

% Define some commands to keep the formatting separated from the content 
\newcommand{\keyword}[1]{\textbf{#1}}
\newcommand{\tabhead}[1]{\textbf{#1}}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\file}[1]{\texttt{\bfseries#1}}
\newcommand{\option}[1]{\texttt{\itshape#1}}

%----------------------------------------------------------------------------------------


\section{Recognition tasks}

The study of human intelligence, and the study of artificial
intelligence, form two major intertwining areas of modern research.
The attempt to algorithmically mimic or exceed human perceptual and
cognitive capabilities not only advances the application of artificial
intelligence for industrial applications, but also sheds light on the
nature of biological intelligence, and the nature of intelligence in
general.  One of the key capabilities of an intelligent system,
natural or artificial, is the ability to recognize objects, agents,
and signs in the environment based on input data.  Human brains have a
remarkable ability to recognize objects, faces, spoken syllables and
words, and written symbols or words, and this recognition ability is
essential for everyday life.  While researchers in artificial
intelligence have attempted to meet human benchmarks for these
classical recognition tasks for the last X decades, only very recent
advances in machine learning, such as deep neural networks, have
allowed algorithmic recognition algorithms to approach or exceed human
performance [CITE].

Within the statistics and machine learning literature, the usual
formalism for studying a recognition task is to pose it as a
\emph{multi-class classification} problem.  One delineates a finite
set of distinct entities which are to be recognized and distinguished,
which is the \emph{label set} $\mathcal{Y}$.  The input data is
assumed to take the form of a finite-dimensional real \emph{feature
  vector} $X \in \mathbb{R}^p$.  Each input instance is associated
with exactly one true label $Y \in \mathcal{Y}$.  The solution to the
classification problem takes the form of an algorithmically
implemented \emph{classification rule} $h$ that maps vectors $X$ to
predicted labels $\hat{Y} \in \mathcal{Y}$.  The classification rule
can be constructed in a data-dependent way: that is, one collects a
number of labelled \emph{training observations} $(X_1, Y_1)$ which is
used to inform the construction of the classification rule $h$.  The
success of the classification rule $h$ is measured by the \emph{expected loss} or \emph{risk},
which in the case of zero-one loss takes the form
\[
\text{Risk}_{0-1}(h) = \Pr[h(X) \neq Y],
\]
where the probability is defined with reference to the unknown
population joint distribution of $(X, Y)$.  A common approach for
constructing a classifier $h$ is \emph{empirical risk minimization} [CITE],
which constructs $h$ by minimizing the objective function
\[
\text{EmpiricalRisk}_{h \in \mathcal{H}}(h) = \frac{1}{n} \sum_{i=1}^n I(h(X) \neq Y)
\]
where $\mathcal{H}$ is some pre-specified function class.

However, a limitation of the usual multi-class classification
framework for studying recognition problems is the assumption that the
label set $\mathcal{Y}$ is finite and known in advance.  When
considering human recognition capabilities, it is clear that this is
not the case.  Our ability to recognize faces is not limited to some
pre-defined, fixed set of faces; same with our ability to recognize
objects in the environment.  Humans learn to recognize novel faces and
objects on a daily basis.  And, if artificial intelligence is to fully
match the human capability for recognition, it must also possess the
ability to add new categories of entities to its label set over time;
however, at present, there currently exists a void in the machine
learning literature on the subject of the online learning of new
classes in the data [CITE].

The central theme of this thesis is the study of \emph{randomized
  classification}, which can be motivated as an extension of the
classical multi-class classification framework to accommodate the
possibility of growing or infinite label sets $\mathcal{Y}$. The basic
approach taken is to assume an infinite or even continuous label space
$\mathcal{Y}$, and then to study the problem of classification on
finite label sets $S$ which are randomly sampled from $\mathcal{Y}.$
This, therefore defines a \emph{randomized classification} problem
where the label set is finite but may vary from instance to instance.
One can then proceed to answer questions about the variability of the
performance due to randomness in the labels, or how performance
changes depending on the size of the random label set.

An additional set of applications of the randomized classification
framework lies in its connection to information theory.  Randomized
classification is the natural analogue of the \emph{random code}
models first studied by Claude Shannon.  Furthermore, it becomes
possible to prove extensions of Fano's inequality to the case of
continuous $X$ and $Y$ by means of randomized classification.
Therefore, randomized classification can be used as a means of
inferring mutual information.

The rest of the thesis is organized as follows.  The remaining
sections in this chapter deal with background material on supervised
learning and information theory, as well as the application of both to
neuroscience, which forms a major motivation for the current work.
Chapter 2 introduces the concept of randomized classification, and
also establishes some variability bounds which will be used later in
the development of inference procedures.  Chapter 3 studies the
dependence of classification accuracy on the label set size in
randomized classification, and a practical method for predicting the
accuracy-versus-label set size curve from real data.  Chapter 4 and 5
deal with the applications of randomized classification to the
estimation of mutual information in continuous data: chapter 4 derives
a lower confidence bound for mutual information under very weak
assumptions, while chapter 5 works within an asymptotic
high-dimensional framework which leads to a more powerful but less
robust estimator estimate of mutual information.

\section{Information and Discrimination}

In studying the problem of recognition, we make use of two closely
related frameworks: firstly, the multi-class classification framework
from the statistics and machine learning literature, and secondly, the
concepts of information theory.  From a broader perspective, this is
hardly unusual, since concepts such as entropy, divergence, and mutual
information are commonly applied in theoretical statistics and machine
learning.  Furthermore, information theory, theoretical statistics,
and machine learning are based on the same foundation:
measure-theoretic probability theory; one could even say that all
three disciplines are subfields of applied probability.  However,
while the three sub-fields may appear very similar from a mathematical
perspective, some differences arise if we examine the kinds of
intuitions and assumptions that are characteristic of the literature
in each area.

A common problem to all three subfields is the inference of some
unobserved quantity on the basis of observed quantities.  In classical
statistics, the problem is to infer an unknown parameter; in
supervised learning, the problem is to predict an unobserved label or
response $Y$; in information theory, the problem is to decode a noisy
message.  Next, the metric for quantifying achievable performance
differs between the three disciplines.  In classical statistics, one
is concerned with the variance of the estimated parameter, or
equivalently, the Fisher information.  In machine learning, one seeks
to minimize (in expectation) a \emph{loss} function which measures the
discrepancy between the prediction and the truth.  In information
theory, one can measure the quality of the noisy channel (and
therefore, the resulting achievable accuracy) through the \emph{mutual
  information} $I(X; Y)$ between the sender's encoded message $X$ and
the reciever's recieved message $Y$.  If we specialize within machine
learning to the study of classification, then we are concerned with
accurate \emph{discrimination} of the input $X$ according to labels
$Y$.

%% have to reorder the next para, 
The concepts of \emph{information} and \emph{discrimination} are quite
distinct from an intuitive standpoint; however, they are linked at a
fundamental level.  This link can be seen throughout statistics and
machine learning, and in the way we think about statistical problems.
A statistical hypothesis test is \emph{informative} because it
provides evidence that the data behaves according to a certain
hypothesis rather than another: it allows us to \emph{discriminate}
between two potential possibilities.  More generally, a true message
contains \emph{information} if it allows the reciever to understand
that the world is in a certain state and not another: it conveys the
fact that out of two possible sets of world states, that the reciever
is in one state rather than another.  The formalism of
measure-theoretic probability theory provides yet another example of
the conceptual link between information and
discrimination\footnote{Supposing $\Omega$ is a probability space
  defined with respect to a $\sigma$-algebra $\mathcal{F}$, we can
  represent our state of knowledge with a filtration (or
  sub-$\sigma$-algebra) $\mathcal{F}' \subseteq \mathcal{F}$.
  Complete knowledge (zero uncertainty) is represented by the full
  $\sigma$-algebra: that is, $\mathcal{F}' = \mathcal{F}$.  Partial
  knowledge is represented by a coarser filtration, $\mathcal{F}
  \subset \mathcal{F}'$.  The filtration, of course, indicates that
  our knowledge is sufficient to \emph{discriminate} the outcome space
  $\Omega$ into a number of finitely or infinitely many categories.
  The more information we have, (or, the closer we come to complete
  knowledge of the outcome), the more finely we can discriminate the
  realized outcomes given by $\omega \in \Omega$.}.

%% the purpose of this paragraph is to make the link between discrimination and information
Either natural or artificially intelligence recognition systems
must rely on input data that is \emph{informative} of the optimal
response if they are to achieve reasonable discriminative accuracy.
In natural environments, mammals rely on a combination of visual,
auditory, and tactile cues to recognize potential threats in the
environment.  Mammalian brains integrate all of this sensory
information in order to make more rapid and reliable decisions.
Generally, increased diversity and quality of the available sources of
information will lead to more accurate recognition.

This link between the information content of the sensory input and the
achievable discrimination accuracy was first formalized by Claude
Shannon via the concept of \emph{mutual information.}  The mutual
information $I(X; Y)$ quantifies the information content that an input
$X$ holds abut a target of interest, $Y$.  For instance, in the case
of facial identification, the discrimination target $Y$ is a label
corresponding to the identity of the person, and $X$ is an image of
the individual's face.  An image corrupted by noise holds less
information, and correspondingly leads to lower classification
accuracies.

The discrmination problem that Shannon studied--the
\emph{noisy-channel decoding problem}, is extremely similar to the
multi-class classification problem, but also features some important
differences.  A side-by side comparison between the schematics of
multi-class classification and the noisy channel problem is displayed
in Figure \ref{fig:mcc_vs_it}.

\tikzstyle{block} = [rectangle, draw, fill=white, 
    text width=5em, text centered, rounded corners, minimum height=4em]
\tikzstyle{cloud} = [ellipse, draw, fill=white, 
    text width=5em, text centered, rounded corners, minimum height=4em]
\tikzstyle{line} = [draw, -latex']
    
\begin{figure}
\centering
\begin{tabular}{ccc}

Multi-class classification & & Information Theory\\

\begin{tikzpicture}[node distance = 2cm, auto]
    % Place nodes
    \node [block] (init1) {label $Y$};
    \node [cloud, below of=init1] (init2) {distribution $F_{X|Y}$};
    \node [block, below of=init2] (init3) {observation $X$};
    \node [cloud, below of=init3] (init4) {classification rule $h(X)$};
    \node [block, below of=init4] (init5) {estimate $\hat{Y}$};
    % Draw edges
    \path [line] (init1) -- (init2);
    \path [line] (init2) -- (init3);
    \path [line] (init3) -- (init4);
    \path [line] (init4) -- (init5);
\end{tikzpicture} 

& & 

\begin{tikzpicture}[node distance = 2cm, auto]
    % Place nodes
    \node [block] (initA) {message $M$};
    \node [cloud, below of=initA] (initB) {encoder $g(M)$};
    \node [block, below of=initB] (init1) {encoded message $Y$};
    \node [cloud, below of=init1] (init2) {noisy channel $F_{X|Y}$};
    \node [block, below of=init2] (init3) {observation $X$};
    \node [cloud, below of=init3] (init4) {decoder $d(X)$};
    \node [block, below of=init4] (init5) {estimate $\hat{M}$};
    % Draw edges
    \path [line] (initA) -- (initB);
    \path [line] (initB) -- (init1);
    \path [line] (init1) -- (init2);
    \path [line] (init2) -- (init3);
    \path [line] (init3) -- (init4);
    \path [line] (init4) -- (init5);
\end{tikzpicture} 

\end{tabular}
\caption{Comparing the discrimination tasks in multi-class classification and information theory.}
\label{fig:mcc_vs_it}
\end{figure}

We will now review the relevant background for supervised learning and
information theory, to give the context for each side of figure
\ref{fig:mcc_vs_it}.  Afterwards, we will compare and contrast the
supervised learning and information theory, and note what kind of
cross-talk exists between the two related fields, and what new
developments could still arise by way of a dialogue between supervised
learning and information theory.  One such new development is the
\emph{randomized classification} model, since it is a very close
analogue of the \emph{random code} model studied in information
theory.

\subsection{Supervised learning}



\begin{itemize}
\item Supervised learning task is defined using a prediction task.
\item 1. A predictive model is learned using training data
\item 2. The performance of the model on the prediction task is estimated using independent test data
\item Classical examples of prediction tasks: regression and classification
\item Third example: identification
\item Definition of Bayes prediction model
\item General definition of supervised learning task
\item SL performance can be a scalar
\item SL can be used to test for independence
\item Bayes performance satisfies data-processing inequality
\item How SL is interpreted in MVPA as information
\item Section 3, we'll see how Bayes performance can be legitimately considered a measure of information
\end{itemize}

In multi-class classification, we may assume without loss of generality that the data has been generated in the following manner:
\begin{enumerate}
\item First, a label $Y$ is drawn according to some distribution from the label set $\{y_1,\hdots, y_k\}$.
\item Secondly, the new observation $X$ is drawn according to the unknown conditional distribution $F_{X|Y}$.
\item Finally, an estimated label $\hat{Y} = h(X)$ is obtained
  according to a data-dependent classification rule, $h$.
  Typically, $h$ is determined by fitting a model to training data.
\end{enumerate}
In the particular application, the above description may not match the
\emph{causal relationship} between $X$ and $Y$: however, whether $X$
is drawn conditional on $Y$, or $Y$ is drawn conditional on $X$, or
that $(X, Y)$ are drawn from some joint distribution, makes no
difference from the theoretical standpoint, since only the statistical
(and not causal) properties of the joint distribution $(X, Y)$ are
relevant for determining the peformance of the classification rule $h(X)$.

\subsection{Information Theory}\label{sec:intro_mi}

Meanwhile, in the noisy channel model, we assume that the sender wants
to transmit message $M$, out of a finite set of possible messages
$\mathcal{M} = \{1,\hdots, m\}$.  The message must be encoded into a
signal $Y \in \mathcal{Y}$, which is sent through a stochastic channel
$F_{X|Y}$.  Given that a signal $y$ is sent through the channel, the
reciever observes a signal $X$ drawn from the distribution $F_{X|y}$.
The communications problem is to design an encoding function $g(M)$,
which is an injective map from messages $\{1,\hdots,m\}$ to signals in
$\mathcal{M}$, and a corresponding decoding function $d(X)$ which
infers the message $\{1,\hdots, m\}$ from the recieved signal $X$.


While Shannon's theory of information was motivated by the problem of
designing communications system, the applicability of mutual
information was quickly recognized by neuroscientists.  Only four
years after Shannon's seminal paper in information theory (1948),
McKay and McCullough (1952) inaugurated the application of mutual
information to neuroscience.  If $\bX$ and $\bY$ have joint density
$p(\bx, \by)$ with respect to the product measure $\mu_x \times \mu_y$, then the mutual information is defined as
\[
\text{I}(\bX;\bY) = \int p(\bx, \by) \log \frac{p(\bx, \by)}{p(\bx)p(\by)}d\mu_x(\bx) d\mu_y(\by).
\]
where $p(\bx)$ and $p(\by)$ are the marginal densities with respect to
$\mu_x$ and $\mu_y$\footnote{Note that the mutual information is invariant with respect to change-of-measure.}.  Since then, mutual information has enjoyed a
celebrated position in both experimental and theoretical neuroscience.
Experimentally, mutual information has been used to detect strong
dependencies between stimulus features and features derived from
neural recordings, which can be used to draw conclusions about the
kinds of stimuli that a neural subsystem is designed to detect, or to
distinguish between signal and noise in the neural output.
Theoretically, the assumption that neural systems maximize mutual
information between salient features of the stimulus and neural output
has allowed scientists to predict neural codes from signal processing
models: for instance, the center-surround structure of human retinal
neurons matches theoretical constructions for the optimal filter based
on correlations found in natural images [cite].

The mutual information measures the information ``capacity'' of a
channel consisting of an input $\bX$ and an output $\bY$, and
satisfies a number of important properties.
\begin{enumerate}
\item The channel input $\bX$ and output $\bY$ can be random vectors of arbitrary dimension, and the mutual information remains a scalar functional of the joint distribution $P$ of $(\bX, \bY)$.
\item When $\bX$ and $\bY$ are independent, $\text{I}(\bX; \bY) = 0$; otherwise, $\text{I}(\bX; \bY) > 0$.
\item The data-processing inequality: for any vector-valued function $\vec{f}$ of the output space,
\[
\text{I}(\bX; \vec{f}(\bY)) \leq \text{I}(\bX; \bY).
\]
\item Symmetry: $\text{I}(\bX; \bY) = \text{I}(\bY; \bX)$.
\item Independent additivity: if $(\bX_1,\bY_1)$ is independent of $(\bX_2, \bY_2)$, then
\[
\text{I}((\bX_1,\bY_1); (\bX_2, \bY_2)) = \text{I}(\bX_1; \bY_1) + \text{I}(\bX_2; \bY_2).
\]
\end{enumerate}
Three additional consequences result from the data-processing inequality:
\begin{itemize}
\item \emph{Stochastic data-processing inequality}  If $\vec{f}$ is a stochastic function independent of both $\bX$ and $\bY$, then
\[
\text{I}(\bX; \vec{f}(\bY)) \leq \text{I}(\bX; \bY).
\]
This can be shown as follows: any stochastic function $\vec{f}(\bY)$
can be expressed as a deterministic function $\vec{g}(\bY, W)$, where
$W$ is a random variable independent of $\bX$ and $\bY$.
By independent additivity,
\[
\text{I}(\bX; \bY) = \text{I}(\bX; (\bY, W)).
\]
Then, by the data-processing inequality,
\[
\text{I}(\bX; \bY) = \text{I}(\bX; (\bY, W)) \geq \text{I}(\bX; \vec{g}(\bY, W)) = \text{I}(\bX; \vec{f}(\bY)).
\]
\item \emph{Invariance under bijections.} If $\vec{f}$ has an inverse $\vec{f}^{-1}$, then 
\[
\text{I}(\bX; \vec{f}(\bY)) \leq \text{I}(\bX; \bY) = \text{I}(\bX; \vec{f}^{-1}(\vec{f}(\bY))) \leq \text{I}(\bX; \vec{f}(\bY)),
\]
therefore, $\text{I}(\bX; \vec{f}(\bY)) = \text{I}(\bX; \bY)$.
\item \emph{Monotonicity with respect to inclusion of outputs.}  Suppose we have an output ensemble $(\bY_1,\bY_2)$.  Then the individual component $\bY_1$ can be obtained as a projection of the ensemble.  By the data-processing inequality, we therefore have
\[
\text{I}(\bX; \bY_1) \leq \text{I}(\bX; (\bY_1, \bY_2)).
\]
Intuitively, if we observe both $\bY_1$ and $\bY_2$, this can
only \emph{increase} the information we have about $\bX$ compared to
the case where we only observe $\bY_1$ by itself.
\end{itemize}
And it is the property of \emph{invariance under bijections},
inclusive of non-linear bijections, which qualifies mutual information
as a \emph{non-linear measure of dependence.}  Linear correlations are
invariant under scaling and translation, but not invariant
to \emph{nonlinear} bijections.

%As for
%the completeness of the five listed properties: as we know, Shannon's
%mutual information (up to arbitrary scaling factor) is the only
%functional proposed in the literature which satisfies all five
%properties.
Besides the formal definition, there are a number of well-known alternative
characterizations of mutual information in terms of other
information-theoretic quantities: the \emph{entropy} $\text{H}$:
\[
\text{H}_\mu(\bX) = -\int p(\bX) \log p(\bX) d\mu(\bX),
\]
and the \emph{conditional entropy}:
\[
\text{H}_\mu(\bX|\bY) = -\int p(\bY) d\mu_y(\bY) \int p(\bX|\bY) \log p(\bX|\bY) d\mu_x(\bX).
\]
Some care needs to be taken with entropy and conditional entropy since
they are not invariant with respect to change-of-measure: hence the
use of the subscript in the notation $\text{H}_\mu$.  In particular,
there is a difference between \emph{discrete entropy} (when $\mu$ is
the counting measure) and \emph{differential entropy} (when $\mu$ is
$p$-dimensional Lesbegue measure.)  Intutively, entropy measures an
observer's uncertainty of the random variable $\bX$, supposing the
observer has no prior information other than the distribution of
$\bX$. Conditional entropy measures the \emph{expected uncertainty} of
$\bX$ supposing the observer observes $\bY$.

The following identities characterize mutual information in terms of entropy:
\[
\text{I}(\bX; \bY) = \text{H}_{\mu_x \times \mu_y}((\bX, \bY)) - \text{H}_{\mu_x}(\bX) - \text{H}_{\mu_y}(\bY).
\]
\begin{equation}\label{eq:ce_ident}
\text{I}(\bX; \bY) = \text{H}_\mu(\bY) - \text{H}_\mu(\bY|\bX).
\end{equation}
The second identity \eqref{eq:ce_ident} is noteworthy
as being practically important for estimation of mutual information.
Since the entropies in question only depend on the marginal and
conditional distributions of $\bY$, the problem of estimating
$\text{I}(\bX; \bY)$ can be reduced from a $\dim(\bX)
+ \dim(\bY)$-dimensional nonparametric estimation problem to a
$\dim(\bY)$-dimensional problem: hence this identity is a basis of
several methods of estimation used in neuroscience, such as Gastpar
(2014).

However, by symmetry, we also have the flipped identity
\begin{equation}\label{eq:ce_ident2}
\text{I}(\bX; \bY) = \text{H}_\mu(\bX) - \text{H}_\mu(\bX|\bY).
\end{equation}
In neuroscience studies, where $\bX$ is the controlled stimulus, and
$\bY$ is the neural activity, the two mirror pairs \eqref{eq:ce_ident}
and \eqref{eq:ce_ident2} have different interpretations.  Rather than
providing a basis for practical estimation, \eqref{eq:ce_ident2}
provides an \emph{interpretation} of the mutual information.  Loosely
speaking, $\text{H}_\mu(\bX)$ is the uncertainty of $\bX$ before
having observed $\bY$, and $\text{H}_\mu(\bX|\bY)$ is the uncertainty
of $\bX$ after having observed $\bY$, hence $\text{H}_\mu(\bX)
- \text{H}_\mu(\bX|\bY)$ is how much the observation of $\bY$
has \emph{reduced} the uncertainty of $\bX$.  Stated in words,
\[
\text{I}(\bX; \bY) = \text{average reduction of uncertainty about $\bX$ upon observing $\bY$}.
\]

\subsection{Comparisons}

Therefore, we see that in both the multi-class classification problem
and the noisy channel model present examples of discrimination
problems where one must recover some latent variable $Y$ from
observations $X$, where $X$ is related to $Y$ through the family of
conditional distributions $F_{X|Y}$.  One difference is that while in
multi-class classification, $F_{X|Y}$ is unknown and has to be
inferred from data, in the noisy channel model, the stochastic
properties of the channel $F_{X|Y}$ are usually assumed to be known.
For example, for a binary channel where $Y$ consists of an $m$-length
binary string, a commonly studied channel $F_{X|Y}$ generates $X$ by
randomly flipping bits in $Y$ independently with some probability
$\epsilon$.  A second difference is that in the noisy channel model,
there is a choice in how to specify the encoding function $g(M)$,
which affects subsequent performance.  Finally, in the broader
research context, machine learning research has traditionally focused
on multi-class problems with relatively few classes, while information
theory tends to consider problems in asymptotic regimes where the
number of possible messages $m$ is taken to infinity. These
differences were sufficient to explain why little overlap exists in
the respective literatures between multi-class classification and the
noisy channel model.  

%% unusual to put mention this here

However, an interesting development in the machine learning community
has been the application of multi-class classification to problems
with increasingly large and complex label sets.  Consider the
following timeline of representative papers in the multi-class
classification literature:
\begin{itemize}
\item Fisher's Iris data set, \cite{fisher1936use}, $K = 3$ classes
\item Letter recognition, \cite{frey1991letter}, $K = 26$ classes
\item Michalski's soybean dataset, \cite{mickalstd1980learning}, $K = 15$ classes
\item The NIST handwritten digits data set, \cite{grother1995nist}, $K = 10$ classes
\item Phoneme recognition on the TIMIT datset, \cite{clarkson1999use}, $K = 39$ classes
\item Object categorization using Corel images, \cite{duygulu2002object} $K = 371$ classes
\item Object categorization for ImageNet dataset, \cite{deng2010does}, $K = 10,184$ classes
\item The 2nd Kaggle large-scale hierarchical text classification challenge (LSHTC), \cite{partalas2015lshtc}, $K = 325,056$
\end{itemize}
As we can see, in recent times we begin to see classification problems
with extremely large label sets.  In such large-scale classification
problems, or `extreme' classification problems, results for $K \to
\infty$ numbers of classes, like those found in information theory,
begin to look more applicable.

This work focuses on a particular intersection between multi-class
classification and information theory, which is the study of
\emph{random classification tasks.}  In numerous domains of applied
mathematics, it has been found that systems with large numbers of
components can be modelled using randomized versions of those same
systems, which are more tractable to mathematical analysis: for
example, studying the properties of networks by studying random graphs
in graph theory, or studying the performance of combinatorial
optimization algorithms for random problem instances.  Similarly, it
makes sense to posit randomized models of multi-class discrimination
problems.  Since information theorists were the first to study
discrimination problems with large number of classes, we find in the
information theory literature a long tradition of the study of
\emph{random code} models, dating back all the way to Shannon's
seminal 1948 paper.  This thesis is dedicated to the the study of the
analogue of random code models in the multi-class classification
setting: models of \emph{randomized classification.}


%% Make the connection between random codes and randomized classification,
%% point out why randomized classification is a good model for some contemporary problems


%% Link back to Shannon and information theory.  We develop further links between randomized classification and information theory.

\section{Applications of supervised learning and information theory in neuroscience}

The study of naturally intelligent systems, and the study and design
of artificially intelligent systems, form two major intertwining
domains of modern research.  Here, we take \emph{intelligence} to
refer to the property of a system by which it can modulate its
reaction to external inputs in a purposeful manner.  Therefore, by
this definition, an amoeba which seeks food and avoids toxins is
intelligent, as is a gene-regulation network, or a mammalian brain.
Similarly, artificially intelligent algorithms which implement
automated decision-making rules in response to external inputs also
satisfy this definition of intelligence.

A primitive organism may classify percieved objects in its environment
as either beneficial (potential food and resources) or harmful (toxins
and predators), and intelligently respond by means of pursuing the
former and avoiding the latter.  %% note that this example is redundant
Complex organisms, like humans, not
only discriminate in order to make immediate decisions, but also
categorize objects in the world in order to perform intermediate
calculations and carry out contextual reasoning.
%% example?


%% Introduce examples of classification and multi-class classification

Similarly, \emph{artificially intelligent} algorithms and agents will
also discriminate input data into categories.  Very often, these types
of classification and recognition tasks mimic and automate
discrimination tasks that humans already perform, such as:
\begin{itemize}
\item Optical character recognition: recognizing characters from handwritten glyphs.
\item Facial recognition: identifying individuals from images of their faces.
\item Object recognition: identifying objects in photographs and labelling them with the appropriate keyword.
\end{itemize}
However, classification can also be performed on novel types of tasks
where no human substitute exists, such as diagnosis of cancer
phenotype based on thousands of gene expression levels.

While a major use of artificially intelligent classifiers is to
automate routine tasks or to categorize complex data, it is also
scientifically interesting to compare the performance of naturally
intelligent agents (human or animal subjects) versus artificially
intelligent classifiers on discrimination tasks.  One reason is that human
benchmarks on complex classification tasks, such as object
recognition, are often non-trivial to beat, and provide a useful
reference to quantify progress in machine learning.  Yet, another
reason is that the attempt to engineer an artificially intelligent
solution to a natural recognition problem provides insight into the
nature of intelligence in human and animal brains.  We still cannot
fully explain the human capability to quickly locate and identify
objects in a natural scene, but research into the mechanisms of
vision, and attempts to replicate human capabilities for object
recognition, have already provided crucial insight into the
hierarchical nature of mammalian vision.  %% needs citation

The approach of using classifiers as models of cognition is especially
valuable for the problem of understanding specialization in the brain.
Historically, the earliest discoveries of specialized modules in the
brain were due to lesion studies, where patients who had parts of
their brain destroyed due to injury or clinical surgeries also lost
cognitive or motor functionality as a result.  The loss of
functionality established a causal pathway between the lesioned area
and the affected behavior--as, for example, in the case of the
discovery of Broca's area, which was established in this way to be
critical for speech production [CITE].  However, ethical and practical
limitations restrict the use of lesioning as an experimental
technique, and furthermore, lesion studies cannot be applied to
exhaustively isolate the regions of the brain which are specialized
for a given task.  
%% Next part is a bit brief
%% We want to say that training classifiers on parts of brain is like a ``synthetic lesion'' study,
%% but this would be misleading because unlike lesion studies, these cannot establish causality.
Therefore, an alternative method of studying specialization is to
acquire an image of the brain activity, and then to assess the
discriminative performance of classifiers on either the whole brain,
the brain minus a number of ``lesioned'' areas, or isolated regions of
the brain by themselves.  The classifier may achieve a certain
accuracy using the whole brain image, and reduced accuracies using
``lesioned'' images--and, given the removal of the task-critical parts
of the brain in the image, may be reduced to chance accuracy levels.
Therefore, similar to lesion studies, these classification experiments
can reveal specialization in the brain by establishing which parts of
the brain image contain \emph{information} related to the task.
However, an important distinction is that these studies can only
establish association, rather than causality, because actual lesions
to the brain affect the activity patterns of other parts of the brain,
and therefore the effect of lesions cannot actually be completely
simulated by merely masking parts of the brain image.
%% examples where the artificial classifier does mimic the natural classifier

%% ''puzzling'' is being used in a patronizing manner
However, a potentially puzzling aspect of this approach, is that the
structure or dynamics of the artificially intelligent classifier need
not imitate the dynamics of the biological system for the modelling
approach to be useful.  Computational neuroscientists have developed
biological realistic models of neural signalling activity which could
be employed to simulate the neural decision-making process from input
to output, at a very high level of versimilitude.  However, it is
often more useful in practice to model the decision-making process
with much simpler statistical models, such as linear regression.  Even
relatively complex machine learning models, such as deep neural
networks, represent a vast simplification from biological dynamics.
Yet their use can often be justified by the assumption that the
performance achieved on this task by the given classifier is
reflective of the performance that would be achieved by a more
biologically realistic model.  Indeed, this assumption can often be
justified because, as is generally observed in real-world machine
learning applications, several very different types of classifiers
often end up achieving similar performance (when tuned correctly).

How can we explain the correlation in the performance of very
different families of classifiers across problems in a wide range of
domains? In problems where it is hard to a given family of classifiers
to perform well, it is also hard to other families of classifiers.  In
problems where one classifier achieves very high accuracy, many other
families of classifier can achieve high accuracy as well.  

One explanation for this phenomenon is that the input contains a
certain amount of \emph{information} about the output, and that the
amount of information sets fundamental limits on what kind of
classification accuracies can be achieved.  Indeed, the relationship
between information and bounds on discrimination accuracy were first
established by Claude Shannon, who gave the formula for the
\emph{mutual information} between two random variables $X$ and $Y$,
and whose proved in his noisy-channel theorem an asymptotic
relationship between the mutual information and achievable
discrimination accuracy.  Fano [CITE] followed this result with the
equally classical Fano's inequality, which establishes an upper bound
on accuracy as a function of mutual information.

Neuroscientists have used the connection between information and
discrimination in several ways.  One is to sidestep the application of
classifiers altogether, and to directly estimate the mutual
information between brain activity and the task of interest [CITE].  A
second way to to proceed with training classifiers on the data, but
then summarizing the performance of the classifier by the mutual
information implied by the confusion matrix.  Hence, implied mutual
information becomes a error metric for the classification--but one
that is more readily comparable across different classification tasks.

[OK, now what do we do?  We play around with the connection between MI
  and discrimination some more, and find some things.]

We list these properties of mutual information in preparation for
section \ref{sec:axiom_info}, where we prepare a ``minimal'' set of
properties for an information coefficient, and consider how much of
the functionality of the mutual information would be preserved by an
alternative information coefficient satisfying only those minimal
properties.

But what, exactly, is the functionality of mutual information in
neuroscience?  How it is used in practice?  A nice summary of the
applications of mutual information is provided in the introduction of
Gastpar (2014).  Taking their list as a starting point, we briefly
overview the main use-cases of mutual information, and illustrate each
with a representative example.

\subsubsection{Selecting decoding models.}
Neurons carry information via \emph{spike trains}, which are temporal
point processes.  In response to stimulus $\bX$, the neuron produces a
spike train $Y(t)$ where $Y(t) = 1$ indicates a spike at time $t$ and
$Y(t) = 0$ indicates no spiking, for $t \in [0, T]$.

An open question in neuroscience that of how information is encoded in
the spike train.  Put loosely, what is `signal' in the spike train
$Y(t)$ and what is `noise'?  Presumably there exists
some \emph{decoder}--some function $\vec{g}$ of the time series, which
compresses $Y(t)$ to a small dimension while preserving most of the
information about $\bX$.

Nelken et. al. (2005) investigated the neural code in the A1 auditory
cortex of a cat, in response to recorded birdsongs.  The stimulus $\bX
= (X_1, X_2)$ takes the form of 15 different auditory recordings
presented in 24 spatial directions: $X_1 \in \{1,\hdots, 15\}$ indexes
the recording and $X_2 \in \{1,\hdots, 24\}$ indexes the direction of
presentation.  The response $Y(t)$ takes the form of a spike train.

%First, Nelken et al. found a discretization bin width $\delta t$ which
%appeared to preserve most of the information in $Y(t)$.  Let $\bY$
%represent the discretized signal, where
%\[
%\bY_i = I\{\max_{t \in [(i-1)\delta t, i \delta t]} Y(t)\}
%\]
%for $i = 1,\hdots, \lceil \frac{T}{\delta t}\rceil$.  Making the
%working assumption that $\text{I}(\bX;
%Y(t)) \approx \text{I}(\bX; \bY)$, Nelken estimate
%$\text{I}(\bX; \bY)$ as the information in the spike train.

Nelkin et. al. compare the following \emph{decoders} $\vec{g}$ in terms
of the information $\text{I}(\bX; \vec{g}(Y(t)))$.
\begin{itemize}
\item The total spike count $\vec{g}_1(Y(t)) = \sum_t Y(t)$.
\item The mean response time $\vec{g}_2(Y(t)) = \frac{1}{\sum_t Y(t)} \sum_t t Y(t)$.
\item The combination of the two codes: $\vec{g}_{1+2}(Y(t)) = (\vec{g}_1(Y(t)), \vec{g}_2(Y(t)))$.
\end{itemize}
The information of each decoder is compared to the full information of
the signal, $\text{I}(\bX; Y(t))$, which is estimated via binning.

Nelkin et al. find that while the decoder $\vec{g}_1$ reduces the
mutual information by 20 to 90 percent, the information loss from
$\vec{g}_2$ is much less, and barely any information at all is lost
when both decoders are used jointly in $\vec{g}_{1+2}$.  The
scientific conclusion that can be drawn is that since
$\text{I}(\bX; \vec{g}_{1+2}(Y(t)))$ is not much smaller than
$\text{I}(\bX; Y(t))$, the ``signal'' in the spike train is mostly
captured by the spike counts and response times: beyond that, the
detailed temporal pattern of spiking is likely to be ``noise.''  Of
course, an important caveat to their conclusions is
only \emph{individual} neurons are considered: the analysis did not
rule out the possibility that the temporal spiking pattern could yield
information within an \emph{ensemble} of neurons.


%\item Example: Comparison of decoders in Nelken.  
%Property (i) is important to enable model comparison.  Property (iii)
%is needed because relationships may be nonlinear.
\begin{itemize}
\item Example: Redundancy in population code of retina.  
Property (i)-(iii) and (v) are needed to obtain a meaningful measure
of redundancy.
\item In general, symmetry not important, but additivity is desirable 
for measures of redundancy.  Property (ii) can usually be enforced
since any measure needs to have a unique ``minimum'' value for the
case of independence.
\end{itemize}




%Furthermore, given the
%limit to achievable classification in the data, if the functional
%relationship between input and output is not too complicated, then it
%is likely that many of the most commonly used families of machine
%learning models can approach the limit of achievable classification
%[again, within a rather generous margin, like 10 percent.]

%% introduce information theory and MI here?

%% why do we care about information?? 
\section{Random codes and random classification}

A random code model in information theory is one where given some
distribution $\nu$ (typically a uniform distribution) on the space of
transmittable signals $\mathcal{Y}$, we posit that the decoder $g(M)$
is randomly generated, by letting $g(1),\hdots, g(m)$ be identically
and independently assigned to random draws from $\nu$.  For example,
when $\mathcal{Y}$ is the space of $m$-length binary strings, the
encoder $g$ maps indices $1, \hdots, m$ to random $m$-length binary
strings.  The purpose of the random code model is usually to establish
a lower bound on achievable accuracy given some constraints on the
signal space.

Meanwhile, a randomized classification model is one where the label
set $\{y^{(1)},\hdots, y^{(k)}\}$ is not fixed, but randomly sampled.
One defines a label space $\mathcal{Y}$, a family of conditional
distributions $\{F_{X|y}\}_{y \in \mathcal{Y}}$, and a distribution
$\nu$ on $\mathcal{Y}$.  Then the randomized classification model is a
classification task obtained by drawing labels $\{Y^{(1)},\hdots,
Y^{(k)}\}$ iid from $\nu$, generating training data for those
particular labels by drawing observations $X_i^{(j)} \sim
F_{X|Y^{(j)}}$, and where the problem is to construct a classification
rule for assigning new observations $X$ which are drawn from the
mixture
\[
X \sim \frac{1}{k}\sum_{i=1}^k F_{X|Y^{(k)}}
\]
to one of the labels $\{Y^{(1)},\hdots, Y^{(k)}\}.$ As we will see
throughout the thesis, the randomized classification model can be
naturally applied to a large number of multi-class classification
applications, such as facial recognition, where the labels
(e.g. people) can be justifiably modelled as random draws from some
population.  And, even in the majority of classification problems
where the labels cannot be assumed to come from an iid sample,
randomized classification models can still be applied to provide
intuition for the original problem.

The link between random code models and randomized classification
models should now be apparent. Define $Y_i = g(i)$ in the random code
model, so that $Y_i$ are iid drawn from $\nu$.  Fixing a particular
realization of $Y_1,\hdots, Y_k$, the decoding problem is then
evidently a multi-class classification problem with labels
$\{Y_1,\hdots, Y_k\}$.  The only difference between the two models is
that the conditional distributions $F_{X|Y}$ are assumed to be known
in the random code model, and assumed unknown in the randomized
classification model.

But happens when we assume that $F_{X|Y}$ is known, in the multi-class
classification problem?  In fact, it is common to consider the case of
known $F_{X|Y}$ in the machine learning literature, because the
resulting accruacy gives an \emph{upper bound} on achievable
performance in the multi-class classification problem.  This is
because once $F_{X|Y}$ is known, it is possible to define the
\emph{optimal} classification rule, or \emph{Bayes} classification
rule $h_{Bayes}$.  For example, supposing that the performance
criterion is to minimize the zero-one risk $\Pr[\hat{Y} \neq Y]$, then
the Bayes rule is to assign $X$ to the label with the highest
posterior density,
\[
h_{Bayes}(X) = \text{argmax}_{y \in \{y_1, \hdots, y_k\}} f_{X|y}(x) \pi(y)
\]
where $\pi(y)$ is the prior probability of $Y = y$.  Therefore, it is
the same thing to study the Bayes accuracy in a randomized
classification model and the decoding accuracy of a randomized code in
a noisy channel.

Indeed, the analysis of the Bayes accuracy of a randomized
classification model forms the subject of Chapters 2 and 3.  Due to
the aforementioned equivalence, it can be said that a large body of
work dealing with the Bayes accuracy of randomized classification
problems exists in information theory: however, the majority of such
works deal with the limit as $k \to \infty$, and to our knowledge no
analysis has been done for the case of finite $k$, which is the
relevant scenario for multi-class classification.  There is good
reason for this lacuna in the information theory literature, which is
that since information theorists are concerned with understanding the
properties of \emph{optimal} coding schemes, it follows that
randomized coding schemes are only interesting insofar as that they
give good approximations to optimal coding schemes.  However, in the
classification setting, we may be interested in studying randomized
classification for its own sake, and not merely as a means to obtain
lower bounds or estimates for another problem.  Therefore, Chapter 2
presents novel results on the statistical properties of the Bayes
accuracy in the randomized classification model.  Meanwhile, Chapter 3
studies an interesting application of the randomized classification
problem, which is to analyze the dependence of the classification
accuracy on the size of the label set.  This analysis yields a novel
method for `performance extrapolation' in real-world classification
problems, meaning that our method can be used to estimate the
classification accuracy on a large multi-class classification problem
using data from only a subsample of the classes in the larger problem.
