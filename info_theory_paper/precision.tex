\title{Quantifying the precision of decoding models for high-dimensional stimuli}
\author{Charles Zheng and Yuval Benjamini}
\date{\today}

\documentclass[12pt]{article} 

% packages with special commands
\usepackage{amssymb, amsmath}
\usepackage{epsfig}
\usepackage{array}
\usepackage{ifthen}
\usepackage{color}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{mathtools}
\usepackage{csquotes}
\definecolor{grey}{rgb}{0.5,0.5,0.5}

\begin{document}
\maketitle

\newcommand{\tr}{\text{tr}}
\newcommand{\E}{\textbf{E}}
\newcommand{\diag}{\text{diag}}
\newcommand{\argmax}{\text{argmax}}
\newcommand{\Cov}{\text{Cov}}
\newcommand{\Var}{\text{Var}}
\newcommand{\argmin}{\text{argmin}}
\newcommand{\Vol}{\text{Vol}}
\newcommand{\comm}[1]{}
\newcommand{\indep}{\rotatebox[origin=c]{90}{$\models$}}
\newcommand{\Cor}{\text{Cor}}


\begin{abstract}
The analysis of encoding and decoding models is a common theme in both
cell recording studies and in neuroimaging.  A basic measure of the
precision of a decoder is its accuracy at distinguishing $k$ different
stimuli. However, the fixed-$k$ accuracy becomes insensitive beyond
limited range of precision: low-precision decoders saturate at the
chance accuracy $1/k$, while high-precision decoders saturate near
perfect accuracy.  On the other hand, the entire curve of accuracies
for $k = 2,3,...$ provides a detailed and interpretable
characterization of decoder performance.  However, due to limited
sampling, usually only a portion of the curve can be estimated:
furthermore, it is unclear how to summarize the information in the
curve by a single statistic.  We show that under a high-dimensional
limits, the mutual information becomes a sufficient statistic for
reconstructing the entire accuracy curve, therefore suggesting the
adoption of the mutual information as measure of decoder precision.
Based on our theory, we develop a novel estimator of mutual
information suited for high-dimensional settings (such as those found
in neuroimaging), and also a procedure for extrapolating the accuracy
curve to arbitrarily many stimuli.
\end{abstract}


\section{Introduction}
Both computational and cognitive neuroscience are concerned with
understanding brain function: while computational neuroscience is
concerned with understanding functionality at the level of the spiking
behavior of individual neurons and small neural populations, cognitive
neuroscience tends to emphasize functionality at the level of
macroscale regions of the interest in the brain.  While the recording
technologies, motivating questions, and analytical methodologies
differ between the two subdisciplines, the conceptualization of brain
functionality in terms of \emph{encoding} and \emph{decoding} models
has been widely applied in both
areas \cite{QuianQuiroga2009}\cite{Naselaris2011}.  In computational
neuroscience, cell recording experiments are conducted to determine
whether spike trains have a temporal and/or correlational
code \cite{Nelken2005}\cite{Hatsopoulos1998}, to examine how the
neural code adapts to changes in stimulus
distribution \cite{Fairhall2001} and whether downstream neurons make
use of higher-order correlations for decoding \cite{Oizumi2010}.
Meanwhile, in neuroimaging studies, functional MRI experiments are
employed to model the receptive fields of early visual areas in the
human brain \cite{Kay2008a}, to examine the semantic encoding of words \cite{Mitchell2008}
or objects \cite{Huth2012}.

The dual perspectives of encoding and decoding originate naturally
from the fact that in examining the link between brain activity and
function, one can either start with brain activity on one end, or with
external stimulation or behavioral observation on the other end.
Starting by exposing the subject to sensory stimuli or prompting the
subject to engage in particular motor tasks, one can search for areas
in the brain which respond to the task: in other words, one can test
to see which areas of the brain \emph{encode} the given stimulus.  In
the other direction, one seeks to understand the functionality of a
given brain region: in other words, how to \emph{decode} brain
activity in that region.

Formulation of encoding models is relatively straightforward, since
one needs only to characterize the observed brain response to a given
stimulus.  One can further ask how to distinguish between signal and
noise in the encoding mechanism \cite{Nelken2005}, or in complex
stimuli, seek a linearizing feature set which reveals the nature of
the brain representation \cite{Naselaris2011}.  However, the
establishment of complete decoding models is much less amenable to
experiemental manipulation, since to exhaustively characterize the
functionality of a neuron, one would have to know in advance the type
of information it encodes.  Early advances in decoding often depended
on strokes of luck: Hubel \cite{Hubel1982} originally discovered the
existence of neurons with orientation-sensitive receptive fields due
to the vigorous response of a cell to the perfectly angled shadow of a
glass slide that they were inserting into the ophthalmoscope.  Yet,
even now, the goal of completely characterizing the function of a
given brain region remains a difficult task, with the most promising
approach being a \emph{reverse inference}
procedure \cite{Poldrack2006} which aggregates information from the
literature about activity-functionality relationships.

A more feasible goal is to establish the \emph{precision} with which a
neuron can decode a particular type of feature.  This can be
accomplished by first training an encoding model, and then inverting
the encoding model using Bayes' rule to obtain a decoding
model \cite{Oram1998}\cite{QuianQuiroga2009}\cite{Naselaris2011}.  

By decoding \emph{precision}, we mean the specificity which we can
identify or reconstruct the stimulus based on the neural response.  As
such, in our view, the term decoder \emph{precision} is more or less
synonymous with terms such as decoder \emph{performance} or
decoder \emph{accuracy} as they are used in the literature.  However,
we choose the word \emph{precision} in particular, because it
communicates the idea that the essential quality of a good decoder is
that it allows one to confidently and precisely infer the stimulus.

Measures of decoding precision can be used to support several
different kinds of scientific inferences.  When there exist multiple
plausible encoding models--for instance, a model where stimulus
information is encoded solely by average firing rate versus a model
where inter-spike timings also carry information--the precision of the
decoder can be used as a basis for deciding the best encoding model.
For two encoding models with equal complexity, such as comparing two
different types of receptive field models, the model with better
decoding precision could be considered the more plausible model.  In
the case where a more complex encoding model is compared to a strictly
simpler model--such as comparing a model with a temporal code versus a
model only incorporating average firing rate, a substantial
improvement in decoding precision for the more complex model is needed
to demonstrate its validity, since in the null hypothesis where the
simpler model is correct, the more complex model should still have
approximately equal decoding performance.

Yet another application of decoding precision is to track the
adaptivity of the neural code.  Fairhall \cite{Fairhall2001} recorded
the output of a motion-sensitive neuron in a fly in response to a
visual stimulus with changing angular velocity.  Changing the variance
of the stimulus results in rapid adaptation: the neural code starts
adapting to the change in stimulus distribution within tens of
milliseconds, which is reflected by an increased or decreased
precision (as measured by mutual information) in resolving angular
velocity to match the variance of the stimulus.  More generally,
comparisons of decoding precisions between different conditions can
show how the encoded information increases or decreases across
experimental conditions.  Kayser \cite{Kayser2010} demonstrated how
the mutual information between a sound stimulus and neurons in the
auditory cortex increased when the subjects were also presented a
matching visual stimulus (e.g. showing a picture of a lion roaring
while playing the sound of a lion's roar.)

Differing types and parameterizations of stimuli naturally lead to
differing measures of decoding precision.  For stimuli which can be
parameterized by a scalar $x$, the precision can be measured by the
squared correlation coefficient $R^2$ \cite{Abbott1994}.  However, the
resulting measure of precision is not invariant to scaling of the
parameterization: for instance, the choice of whether to parameterize
volume on an absolute scale or a logarithmic scale.  The mutual
information \cite{Shannon1948} between the stimulus and the predicted
stimulus is invariant to the parameterization of the stimulus.  Due to
its invariance and a number of other properties, the mutual
information is widely used to measure the precision of the neural code
in cell recording studies, both for single-neuron decoding
models \cite{Borst1999} and for population coding
models \cite{QuianQuiroga2009}\cite{Ince2010}.

However, the difficulties of estimating mutual information in small
samples has been widely recognized, with a large literature on bias
correction methods \cite{Panzeri2007}\cite{Paninski}.  Methods for
bias correction have been developed for three different sample size
regimes: the moderate-sample regime, where the number of observations
is larger than the number of stimulus-response
pairs\cite{Miller1955}\cite{Strong1998}\cite{Treves1995}, the
undersampled regime, where the number of observations is less than the
number of stimulus-response pairs \cite{Nemenman2004}, and
a \emph{stimulus-undersampled} regime, where only a small fraction of
possible stimuli are sampled, but with a large number of observations
for each of the sampled stimuli \cite{Gastpar2009}.  Nevertheless,
even the bias-corrected estimates may be unusably inaccurate in
problems of moderate dimensionality, since the cardinality of response
space grows exponentially with the dimensionality.  In such cases,
alternative approaches for estimating the mutual information include
the assumption of a parametric model \cite{Brunel1998}\cite{Gastpar2009}\cite{Yarrow2012}, or usage of
the maximum entropy principle to obtain bounds on the mutual
information subject to the empirical moments of a certain
order \cite{Ince2009}\cite{Globerson2009}.

Perhaps due to the technical difficulties of estimating mutual
information in high dimensions, mutual information has never, to our
knowledge, been used as a measure of decoding precision in
neuroimaging studies, although it has been proposed for the purpose of
bypassing the modelling of the hemodynamic response function for
single-voxel analyses \cite{FuhrmannAlpert2007}.  Instead, a variety
of methods are employed to characterize the precision of decoding
models, depending on the nature of the stimulus and the experimental
setup.

In task fMRI experiments where stimuli are drawn from a number of
disjoint semantic categories-- for instance, `birds', `insects', and
`mammals' as in \cite{Connolly2012}, it is natural to construct a
decoder which outputs the predicted category of a stimulus as a
function of the response.  Such a decoder is known as
a \emph{classifier} in the machine learning
literature \cite{Hastie2009a}, and a natural measure of classifier
precision is the probability that the decoder outputs the correct
category on a new, randomly drawn test example, which is
the \emph{classification accuracy}.

In experiments where the subject is presented a number of
parameterized stimuli are drawn from a continuous distribution (such
as natural images or sounds), there are two types of decoders which
can be constructed.  In the first case, one constructs a decoder which
estimates the parameters of the stimulus which we call
a \emph{reconstructor}: the precision of such a decoder is measured by
the correlation between the estimated and true parameter vector
\cite{Pasley2012} \cite{Nishimoto2011}\cite{Naselaris2009}.
In the second case, one constructs a decoder which picks the most
likely stimulus from a finite library of examples \emph{which includes
the true stimulus} \cite{Kay2008a}\cite{Mitchell2008}.  Since the true
stimulus is included in the library, the task is to `identify' the
correct stimulus from the library.  A natural measure of decoder
performance is therefore the probability of correct identification.
However, note that this probability is dependent on the arbitrary
choice of the size of the exemplar library: a different choice for
library size therefore results in a different measure of precision.
We refer to the probability of correct classification for a library of
$k$ exemplars as the \emph{$k$-example identification accuracy}.

In their respective domains, these different measures of precision
suffice to make inferences on many interesting scientific questions:
to list a few examples, showing the superiority of a Gabor filters
versus center-surround filters for modeling the receptive fields of V1
and V2 neurons \cite{Kay2008a}, or demonstrating that brain activity
in response to viewing an Engish noun can be predicted from word
association frequencies \cite{Mitchell2008}.  

A commonality to all applications of decoding models in neuroimaging
is the pairwise comparison of two decoding models (Gabor
vs. retinotopic) or the comparison of a single decoding model to
chance accuracy.  Looking ahead to anticipate what kinds of analyses
might be employed in the future based on neuroimaging data, it is
suggestive to note that the earliest decoding studies in the cell
recording literature also involved comparisons between two or three
different decoders \cite{Eckhorn1976}.  However, as neuroscientists
began to consider questions of population coding, analyses of the
redundancy between neurons started to make use of comparisons between
large numbers of decoders: for a population of $N$ neurons, one might
compare the precision of a decoder (mutual information) based on the
entire ensemble, compared to the precisions of decoders based on each
of the $N$ individual neurons.  Furthermore, one can make the same
comparison for a range of different ensemble sizes $N$.  As questions
about the redundancy of the neural code are relevant on both the micro
scale (the domain of cell recording studies) and the macro scale (the
domain of neuroimaging), it is safe to assume that similar analyses,
requiring comparisons of large numbers of decoders, will emerge in
neuroimaging studies.  Already in the functional MRI literature, we
see similar decompositions of decoding accuracy versus ensemble
size \cite{Kay2008a}, but another possible type of decomposition would
be to compare decoding performance as the number of stimulus features
is varied, rather than the number of voxels.

The scaling properties of mutual information are highly advantageous
when comparing multiple decoders, which could potentially span a wide
range of decoding precision: for instance, a single neuron versus an
ensemble of thousands of neurons.  In contrast, classification
accuracy, $k$-class identification accuracy and reconstruction
accuracy all suffer from the issue of \emph{limited dynamic range}:
that is, they are only effective at measuring precision within a
certain range.

Let us illustrate with the example of identification accuracy.  A low
precision decoder, such as a decoder based on a single voxel, may have
an accuracy which is so close to chance accuracy, $1/k$, as to be
statistically indistinguishable from chance based on the data.  On the
other hand, a sufficiently high-precision decoder may face the
opposite problem, where it achieves perfect classification on the
limited number of test examples.  Any empirical estimate of
identification accuracy can only be used to accurately rank decoders
which have accuracies sufficiently bounded away from both $1/k$ and 1.
The same issue applies to reconstruction accuracy (bounded between 0
and 1) and classification accuracy (bounded between $1/k$ and 1, where
$k$ is the number of classes): any bounded measure of precision is
ineffective at comparing decoders which are too close to either the
upper bound or lower bound of achievable precision.

In practice, the solution to this issue is to find a measure of
precision which is well-suited for all of the decoders that needed to
be compared.  If there are two encoding models which both achieve
perfect classification on the test set, then perhaps the more
demanding measure of reconstruction accuracy can be used to
distinguish them.  However, this strategy begins to become impractical
as the number of decoders to be compared increases.  One wishes to
relate the decoding precision of an $N$-voxel ensemble for $N$
spanning from 1 to 10000: however, any bounded measure of precision
which is suitably stringent for distinguishing $N=9999$ from $N=10000$
would fail for comparing $N=1$ to $N=2$, and vice-versa.

We have seen that one solution to this predicament is to use an
unbounded measure of precision which can remain sensitive to
variations in precision across a large dynamic range: for instance,
the mutual information.  Yet, given the difficulty of estimating the
mutual information in high-dimensional settings, one might consider
another approach: to develop a systematic means for comparing decoders
by using multiple (easily estimated) precision measures, each of which
may only capture a limited range of precisions, but which collectively
span a sufficiently large range of precisions to include all of the
decoders being compared.  Our contribution in this paper is to show
that both of these approaches--the estimation of mutual information,
and the comparison of decoders based on a range of decoding metrics,
turn out to be the very same problem in high-dimensional settings.
The \emph{identification accuracy curve}, which we define as the
collection of all $k$-class identification accuracies for $k \geq 2$,
can be used to compare a collection of decoders over a large span of
precisions.  Yet, a recent theoretical result\cite{Zheng2016} shows
that the identification accuracy curve for the Bayes decoder (the
optimal decoder) is determined by the mutual information in a certain
high-dimensional regime.  While it is generally not feasible to
approximate the Bayes decoder in high-dimensional settings, we use
this result to define the \emph{implied information} for a non-Bayes
(suboptimal) decoder.  The implied information, $I_{implied}$, is not
the true mutual information between the stimulus and response, but it
provides a means of comparing two accuracy curves (estimate the
implied information from each, and then compare the estimates), as
well as providing an unbounded measure of decoding precision which,
similar to mutual information, has desirable scaling properties for
the purpose of comparing decoders spanning a range of precisions.

\section{Methods}

\begin{itemize}
\item Computation of $k$-example identification curve
\item Estimation of $I_{implied}$ based on Zheng and Benjamini (2016). What we have to add in the new paper is how to estimate $I$ from multiple $k$ rather than single $k$ as we had in ZB 2016
\end{itemize}

\section{Theory}

\begin{itemize}
\item When will the method work well?
\item Explain the conditions of ZB 2016 using examples from neuroimaging
\item ZB 2016 fails when stimulus is too low-dimensional--for example, arm reaching angle
\item ZB 2016 fails when stimulus is drawn from multimodal distribution--for example, half of the pictures are houses and half are faces
\item How can we diagnose the assumptions? Testing goodness-of-fit of identification curve
\end{itemize}

\section{Simulations}

\begin{itemize}
\item Simulations which illustrate points made in theory section
\item Low-dimensional sim (bad)
\item High-dimensional sim (good)
\item High-dimensional but bimodal (bad)
\end{itemize}

\section{Real-data examples}

Examples using Kay et al data:
\begin{itemize}
\item Comparison of different feature models (subsets of pyramid levels)
\item Comparison of differing voxel numbers
\item Effect of voxel resolution (by averaging neighboring voxels into bigger voxels)
\end{itemize}

\bibliography{neuroinfo}{}
\bibliographystyle{plain}

\end{document}












A common goal in neuroscience experiments is understand how some
aspect of behavior, cognition, or sensation is reflected in brain
activity:




A fundamental challenge of computational neuroscience is to understand
how information about the external world is processed and represented
in the brain.


Each individual neuron aggregates the incoming
information into a single sequence of spikes--an output which is too
simplistic by itself to capture the full complexity of sensory
input. Only by combining the signals from massive ensembles of neurons
is it possible to reconstruct our complex representation of the
world. Nevertheless, neurons form hierarchies of specialization within
neural circuits, which are further organized in various specialized
regions of the brain.  At the lowest level of the hierarchy--individual neurons,
it is possible to infer and interpret the functional relationship between
a neuron and stimulus features of interest using single-cell recording technologies.
Due to the inherent stochasticity of the neural output, it is natural to
view the neuron as a noisy channel, and use mutual information
to quantify how much of the stimulus information is encoded by the neuron.
Moving up the hierarchy to the the macroscale level of organization in the
brain requires both different experimental methodologies and 
new approaches for summarizing and inferring measures of
information in the brain.

Shannon's mutual information $I(X; Y)$ is fundamentally a measure of dependence
between random variables $X$ and $Y$, and is defined as
\[
I(X;Y) = \int p(x, y) \log \frac{p(x, y)}{p(x)p(y)}dxdy.
\]
Various properties of $I(X; Y)$ make it ideal for quantifying the information between
a random stimulus $X$ and the signaling behavior of an ensembles of neurons, $Y$ ~\cite{Borst1999}.
A leading metaphor is that of a noisy communications channel; the mutual
information describes the rate at which $Y$ can communicate bits from
$X$.  This framework is well-suited for summarizing the properties of
a single neuron coding external stimulus information; indeed,
experiments studying the properties of a single or a small number of
neurons often make use of the concept of mutual information in
summarizing or interpreting their results ~\cite{QuianQuiroga2009}. However,
estimating mutual information for multiple channels require large and
over-parameterized generative models.  For instance, one can tractably
estimate mutual information by assuming a multivariate Gaussian model:
however, this approach essentially assumes a linear relationship
between the input and output, and hence fails to quantify nonlinear
dependencies.  As the complexity of stimuli and the number of output
channels increases, these models are hard or impossible to estimate
without gross over-fitting.  As new technologies for simultaneous measurement
of multiple brain regions developed, such as functional MRI, it became
increasingly difficult to quantify information at such scales under the classical approach.
 
Machine learning algorithms showed a way forward: a seminal work
by Haxby (2001) proposed to quantify the information in multiple
channels by measuring how well the stimulus can be identified from the
brain responses, in what is known as ``multivariate pattern analysis''
(MVPA). To demonstrate that a particular brain region responds to a
certain type of sensory information, one employs supervised learning
to build a classifier that classifies the stimulus class from the
brain activation in that region. Classifiers that achieve above-chance
classification accuracy indicate that information from the stimulus is
represented in the brain region. In principle, one could just as well
test the statistical hypothesis that the Fisher information or mutual
information between the stimulus and the activation patterns is
nonzero. But in practice, the machine learning approach enjoys several
advantages: First, it is invariant to the parametric representation of
the stimulus space, and is opportunistic in the parameterization of
the response space. This is an important quality for naturalistic
stimulus-spaces, such as faces or natural images. Second, it scales
better with the dimensionality of both the stimulus space and the
responses space, because a slimmer discriminative model can be used
rather than a fully generative model.

Nevertheless, classification error is problematic for quantifying the
strength of the relation between stimulus and outputs due to its
arbitrary scale and strong dependence on experimental
choices. Classification accuracy depends on the particular choice of
stimuli exemplars employed in the study and the number of partitions
used to define the classes for the classification task. The difficulty
of the classification task depends on the number of classes defined:
high classification accuracy can be achieved relatively easily by
using a coarse partition of stimuli exemplars into classes. In a
meta-analysis on visual decoding, Coutanche et al (2016) quantified
the strength of a classification study using the formula
\[
\text{decoding strength} = \frac{\text{accuracy} - \text{chance}}{\text{chance}}.
\]
Such an approach may compensate for the differences in accuracy due
purely to choice of number of classes defined; however, no theory is
provided to justify the formula. In contrast, mutual information has
ideal properties for quantitatively comparing information between
different studies, or between different brain regions, subjects,
featurization models, or modalities. Not only is the mutual
information defined independently of the arbitrary definition of
stimulus classes (albeit still dependent on an implied distribution
over stimuli), it is even meaningful to discuss the difference between
the mutual information measured for one system and the mutual
information for a second system.

Hence, a popular approach which combines the strengths of the machine
learning approach and the advantages of the information theoretic
approach is to obtain a lower bound on the mutual information by using
the confusion matrix of a classifier.  This is the most popular
approach for estimating mutual information in neuroimaging studies,
but suffers from known shortcomings (Gastpar 2010, Quiroga 2009).
The idea of linking classification performance to mutual information
dates back to the beginnings of information theory: Shannon's original
motivation was to characterize the minimum achievable error
probability of a noisy communication channel.  More explicitly, Fano's
inequality provides a lower bound on mutual information in relation to
the optimal prediction error, or Bayes error.  Fano's inequality can
be further refined to obtain a tighter lower bound on mutual
information (Tebbe and Dwyer 1968.)  However, all approaches to date
can only obtain a lower bound on the mutual information from
classification error.  In practice, the bound obtained may be a vast
underestimate.

In this paper, we propose a new way to link classification performance
to the implied mutual information. 
To create this link we need to overcome the arbitrary choice of
exemplars, and the arbitrary number of classes K.  Towards this end,
we define a notion of $K$-class \emph{average Bayes error} which is
uniquely defined for any given stimulus distribution and stochastic
mapping from stimulus to response.  The $K$-class average Bayes error
is the expectation of the Bayes error (the classification error
of the optimal classifier) when $K$ stimuli exemplars are drawn
i.i.d. from the stimulus distribution, and treated as distinct
classes.  Hence the average Bayes error can in principle be estimated
if the appropriate randomization is employed for designing the
experiment.

Our main theoretical contributions are (i) the derivation of a tight lower bound
on mutual information as a function of $k$-class average Bayes error, and (ii)
the derivation of an asymptotic relationship between the $K$-class average Bayes error and the mutual
information. Although the $K$-class average Bayes error is defined
independently of the particular choice of stimuli, the quantity still
depends on the choice of number of classes, $K$. Mutual information
provides a quantification of information that does not depend on $K$,
allowing more flexible comparisons and easier interpretation. Our
method allows estimates of the $K$-class Bayes error to be translated
into estimate of the mutual information, and this resulting estimator
of mutual information will be asymptotically independent of the choice
of number of classes $K$.




\end{document}





