\title{Quantifying the precision of decoding models for high-dimensional stimuli}
\author{Charles Zheng and Yuval Benjamini}
\date{\today}

\documentclass[12pt]{article} 

% packages with special commands
\usepackage{amssymb, amsmath}
\usepackage{epsfig}
\usepackage{array}
\usepackage{ifthen}
\usepackage{color}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{mathtools}
\usepackage{csquotes}
\definecolor{grey}{rgb}{0.5,0.5,0.5}

\begin{document}
\maketitle

\newcommand{\tr}{\text{tr}}
\newcommand{\E}{\textbf{E}}
\newcommand{\diag}{\text{diag}}
\newcommand{\argmax}{\text{argmax}}
\newcommand{\Cov}{\text{Cov}}
\newcommand{\Var}{\text{Var}}
\newcommand{\argmin}{\text{argmin}}
\newcommand{\Vol}{\text{Vol}}
\newcommand{\comm}[1]{}
\newcommand{\indep}{\rotatebox[origin=c]{90}{$\models$}}
\newcommand{\Cor}{\text{Cor}}


\begin{abstract}
The analysis of encoding and decoding models is a common theme in both
cell recording studies and in neuroimaging.  A basic measure of the
precision of a decoder is its accuracy at distinguishing $k$ different
stimuli. However, the fixed-$k$ accuracy becomes insensitive beyond
limited range of precision: low-precision decoders saturate at the
chance accuracy $1/k$, while high-precision decoders saturate near
perfect accuracy.  On the other hand, the entire curve of accuracies
for $k = 2,3,...$ provides a detailed and interpretable
characterization of decoder performance.  However, due to limited
sampling, usually only a portion of the curve can be estimated:
furthermore, it is unclear how to summarize the information in the
curve by a single statistic.  We show that under a high-dimensional
limits, the mutual information becomes a sufficient statistic for
reconstructing the entire accuracy curve, therefore suggesting the
adoption of the mutual information as measure of decoder precision.
Based on our theory, we develop a novel estimator of mutual
information suited for high-dimensional settings (such as those found
in neuroimaging), and also a procedure for extrapolating the accuracy
curve to arbitrarily many stimuli.
\end{abstract}


\section{Introduction}
Both computational and cognitive neuroscience are concerned with
understanding brain function: while computational neuroscience is
concerned with understanding functionality at the level of the spiking
behavior of individual neurons and small neural populations, cognitive
neuroscience tends to emphasize functionality at the level of
macroscale regions of the interest in the brain.  While the recording
technologies, motivating questions, and analytical methodologies
differ between the two subdisciplines, the conceptualization of brain
functionality in terms of \emph{encoding} and \emph{decoding} models
has been widely applied in both
areas \cite{QuianQuiroga2009}\cite{Naselaris2011}.  In computational
neuroscience, cell recording experiments are conducted to determine
whether spike trains have a temporal and/or correlational
code \cite{Nelken2005}\cite{Hatsopoulos1998}, to examine how the
neural code adapts to changes in stimulus
distribution \cite{Fairhall2001} and whether downstream neurons make
use of higher-order correlations for decoding \cite{Oizumi2010}.
Meanwhile, in neuroimaging studies, functional MRI experiments are
employed to model the receptive fields of early visual areas in the
human brain \cite{Kay2008a}, to examine the semantic encoding of words \cite{Mitchell2008}
or objects \cite{Huth2012}.

The dual perspectives of encoding and decoding originate naturally
from the fact that in examining the link between brain activity and
function, one can either start with brain activity on one end, or with
external stimulation or behavioral observation on the other end.
Starting by exposing the subject to sensory stimuli or prompting the
subject to engage in particular motor tasks, one can search for areas
in the brain which respond to the task: in other words, one can test
to see which areas of the brain \emph{encode} the given stimulus.  In
the other direction, one seeks to understand the functionality of a
given brain region: in other words, how to \emph{decode} brain
activity in that region.

Formulation of encoding models is relatively straightforward, since
one needs only to characterize the observed brain response to a given
stimulus.  One can further ask how to distinguish between signal and
noise in the encoding mechanism \cite{Nelken2005}, or in complex
stimuli, seek a linearizing feature set which reveals the nature of
the brain representation \cite{Naselaris2011}.  However, the
establishment of complete decoding models is much less amenable to
experiemental manipulation, since to exhaustively characterize the
functionality of a neuron, one would have to know in advance the type
of information it encodes.  Early advances in decoding often depended
on strokes of luck: Hubel \cite{Hubel1982} originally discovered the
existence of neurons with orientation-sensitive receptive fields due
to the vigorous response of a cell to the perfectly angled shadow of a
glass slide that they were inserting into the ophthalmoscope.  Yet,
even now, the goal of completely characterizing the function of a
given brain region remains a difficult task, with the most promising
approach being a \emph{reverse inference}
procedure \cite{Poldrack2006} which aggregates information from the
literature about activity-functionality relationships.

A more feasible goal is to establish the \emph{precision} with which a
neuron can decode a particular type of feature.  This can be
accomplished by first training an encoding model, and then inverting
the encoding model using Bayes' rule to obtain a decoding
model \cite{Oram1998}\cite{QuianQuiroga2009}\cite{Naselaris2011}.

Measures of decoding precision can be used to support several
different kinds of scientific inferences.  When there exist multiple
plausible encoding models--for instance, a model where stimulus
information is encoded solely by average firing rate versus a model
where inter-spike timings also carry information--the precision of the
decoder can be used as a basis for deciding the best encoding model.
For two encoding models with equal complexity, such as comparing two
different types of receptive field models, the model with better
decoding precision could be considered the more plausible model.  In
the case where a more complex encoding model is compared to a strictly
simpler model--such as comparing a model with a temporal code versus a
model only incorporating average firing rate, a substantial
improvement in decoding precision for the more complex model is needed
to demonstrate its validity, since in the null hypothesis where the
simpler model is correct, the more complex model should still have
approximately equal decoding performance.

Yet another application of decoding precision is to track the
adaptivity of the neural code.  Fairhall \cite{Fairhall2001} recorded
the output of a motion-sensitive neuron in a fly in response to a
visual stimulus with changing angular velocity.  Changing the variance
of the stimulus results in rapid adaptation: the neural code starts
adapting to the change in stimulus distribution within tens of
milliseconds, which is reflected by an increased or decreased
precision (as measured by mutual information) in resolving angular
velocity to match the variance of the stimulus.  More generally,
comparisons of decoding precisions between different conditions can
show how the encoded information increases or decreases across
experimental conditions.  Kayser \cite{Kayser2010} demonstrated how
the mutual information between a sound stimulus and neurons in the
auditory cortex increased when the subjects were also presented a
matching visual stimulus (e.g. showing a picture of a lion roaring
while playing the sound of a lion's roar.)

Differing types and parameterizations of stimuli naturally lead to
differing measures of decoding precision.  For stimuli which can be
parameterized by a scalar $x$, the precision can be measured by the
squared correlation coefficient $R^2$ \cite{Abbott1994}.  However, the
resulting measure of precision is not invariant to scaling of the
parameterization: for instance, the choice of whether to parameterize
volume on an absolute scale or a logarithmic scale.  The mutual
information \cite{Shannon1948} between the stimulus and the predicted
stimulus is invariant to the parameterization of the stimulus.  Due to
its invariance and a number of other properties, the mutual
information is widely used to measure the precision of the neural code
in cell recording studies, both for single-neuron decoding
models \cite{Borst1999} and for population coding
models \cite{QuianQuiroga2009}\cite{Ince2010}.

However, the difficulties of estimating mutual information in small
samples has been widely recognized, with a large literature on bias
correction methods \cite{Panzeri2007}\cite{Paninski}.  Methods for
bias correction have been developed for three different sample size
regimes: the moderate-sample regime, where the number of observations
is larger than the number of stimulus-response
pairs\cite{Miller1955}\cite{Strong1998}\cite{Treves1995}, the
undersampled regime, where the number of observations is less than the
number of stimulus-response pairs \cite{Nemenmen2004}, and
a \emph{stimulus-undersampled} regime, where only a small fraction of
possible stimuli are sampled, but with a large number of observations
for each of the sampled stimuli \cite{Gastpar2009}.  Nevertheless,
even the bias-corrected estimates may be unusably inaccurate in
problems of moderate dimensionality, since the cardinality of response
space grows exponentially with the dimensionality.  In such cases,
alternative approaches for estimating the mutual information include
the assumption of a parametric model \cite{Gastpar2009}, or usage of
the maximum entropy principle to obtain bounds on the mutual
information subject to the empirical moments of a certain
order \cite{Ince2009}\cite{Globerson2009}.

Perhaps due to the technical difficulties of estimating mutual
information in high dimensions, mutual information has seldom been
employed as a measure of decoding precision in neuroimaging studies,
although it has been proposed for the purpose of bypassing the
modelling of the hemodynamic response function for single-voxel
analyses \cite{FuhrmannAlpert2007}.  Instead, classification
accuracy \cite{Haxby2014} is the dominant measure of precision
for multivoxel decoding models.



\bibliography{neuroinfo}{}
\bibliographystyle{plain}

\end{document}












A common goal in neuroscience experiments is understand how some
aspect of behavior, cognition, or sensation is reflected in brain
activity:




A fundamental challenge of computational neuroscience is to understand
how information about the external world is processed and represented
in the brain.


Each individual neuron aggregates the incoming
information into a single sequence of spikes--an output which is too
simplistic by itself to capture the full complexity of sensory
input. Only by combining the signals from massive ensembles of neurons
is it possible to reconstruct our complex representation of the
world. Nevertheless, neurons form hierarchies of specialization within
neural circuits, which are further organized in various specialized
regions of the brain.  At the lowest level of the hierarchy--individual neurons,
it is possible to infer and interpret the functional relationship between
a neuron and stimulus features of interest using single-cell recording technologies.
Due to the inherent stochasticity of the neural output, it is natural to
view the neuron as a noisy channel, and use mutual information
to quantify how much of the stimulus information is encoded by the neuron.
Moving up the hierarchy to the the macroscale level of organization in the
brain requires both different experimental methodologies and 
new approaches for summarizing and inferring measures of
information in the brain.

Shannon's mutual information $I(X; Y)$ is fundamentally a measure of dependence
between random variables $X$ and $Y$, and is defined as
\[
I(X;Y) = \int p(x, y) \log \frac{p(x, y)}{p(x)p(y)}dxdy.
\]
Various properties of $I(X; Y)$ make it ideal for quantifying the information between
a random stimulus $X$ and the signaling behavior of an ensembles of neurons, $Y$ ~\cite{Borst1999}.
A leading metaphor is that of a noisy communications channel; the mutual
information describes the rate at which $Y$ can communicate bits from
$X$.  This framework is well-suited for summarizing the properties of
a single neuron coding external stimulus information; indeed,
experiments studying the properties of a single or a small number of
neurons often make use of the concept of mutual information in
summarizing or interpreting their results ~\cite{QuianQuiroga2009}. However,
estimating mutual information for multiple channels require large and
over-parameterized generative models.  For instance, one can tractably
estimate mutual information by assuming a multivariate Gaussian model:
however, this approach essentially assumes a linear relationship
between the input and output, and hence fails to quantify nonlinear
dependencies.  As the complexity of stimuli and the number of output
channels increases, these models are hard or impossible to estimate
without gross over-fitting.  As new technologies for simultaneous measurement
of multiple brain regions developed, such as functional MRI, it became
increasingly difficult to quantify information at such scales under the classical approach.
 
Machine learning algorithms showed a way forward: a seminal work
by Haxby (2001) proposed to quantify the information in multiple
channels by measuring how well the stimulus can be identified from the
brain responses, in what is known as ``multivariate pattern analysis''
(MVPA). To demonstrate that a particular brain region responds to a
certain type of sensory information, one employs supervised learning
to build a classifier that classifies the stimulus class from the
brain activation in that region. Classifiers that achieve above-chance
classification accuracy indicate that information from the stimulus is
represented in the brain region. In principle, one could just as well
test the statistical hypothesis that the Fisher information or mutual
information between the stimulus and the activation patterns is
nonzero. But in practice, the machine learning approach enjoys several
advantages: First, it is invariant to the parametric representation of
the stimulus space, and is opportunistic in the parameterization of
the response space. This is an important quality for naturalistic
stimulus-spaces, such as faces or natural images. Second, it scales
better with the dimensionality of both the stimulus space and the
responses space, because a slimmer discriminative model can be used
rather than a fully generative model.

Nevertheless, classification error is problematic for quantifying the
strength of the relation between stimulus and outputs due to its
arbitrary scale and strong dependence on experimental
choices. Classification accuracy depends on the particular choice of
stimuli exemplars employed in the study and the number of partitions
used to define the classes for the classification task. The difficulty
of the classification task depends on the number of classes defined:
high classification accuracy can be achieved relatively easily by
using a coarse partition of stimuli exemplars into classes. In a
meta-analysis on visual decoding, Coutanche et al (2016) quantified
the strength of a classification study using the formula
\[
\text{decoding strength} = \frac{\text{accuracy} - \text{chance}}{\text{chance}}.
\]
Such an approach may compensate for the differences in accuracy due
purely to choice of number of classes defined; however, no theory is
provided to justify the formula. In contrast, mutual information has
ideal properties for quantitatively comparing information between
different studies, or between different brain regions, subjects,
featurization models, or modalities. Not only is the mutual
information defined independently of the arbitrary definition of
stimulus classes (albeit still dependent on an implied distribution
over stimuli), it is even meaningful to discuss the difference between
the mutual information measured for one system and the mutual
information for a second system.

Hence, a popular approach which combines the strengths of the machine
learning approach and the advantages of the information theoretic
approach is to obtain a lower bound on the mutual information by using
the confusion matrix of a classifier.  This is the most popular
approach for estimating mutual information in neuroimaging studies,
but suffers from known shortcomings (Gastpar 2010, Quiroga 2009).
The idea of linking classification performance to mutual information
dates back to the beginnings of information theory: Shannon's original
motivation was to characterize the minimum achievable error
probability of a noisy communication channel.  More explicitly, Fano's
inequality provides a lower bound on mutual information in relation to
the optimal prediction error, or Bayes error.  Fano's inequality can
be further refined to obtain a tighter lower bound on mutual
information (Tebbe and Dwyer 1968.)  However, all approaches to date
can only obtain a lower bound on the mutual information from
classification error.  In practice, the bound obtained may be a vast
underestimate.

In this paper, we propose a new way to link classification performance
to the implied mutual information. 
To create this link we need to overcome the arbitrary choice of
exemplars, and the arbitrary number of classes K.  Towards this end,
we define a notion of $K$-class \emph{average Bayes error} which is
uniquely defined for any given stimulus distribution and stochastic
mapping from stimulus to response.  The $K$-class average Bayes error
is the expectation of the Bayes error (the classification error
of the optimal classifier) when $K$ stimuli exemplars are drawn
i.i.d. from the stimulus distribution, and treated as distinct
classes.  Hence the average Bayes error can in principle be estimated
if the appropriate randomization is employed for designing the
experiment.

Our main theoretical contributions are (i) the derivation of a tight lower bound
on mutual information as a function of $k$-class average Bayes error, and (ii)
the derivation of an asymptotic relationship between the $K$-class average Bayes error and the mutual
information. Although the $K$-class average Bayes error is defined
independently of the particular choice of stimuli, the quantity still
depends on the choice of number of classes, $K$. Mutual information
provides a quantification of information that does not depend on $K$,
allowing more flexible comparisons and easier interpretation. Our
method allows estimates of the $K$-class Bayes error to be translated
into estimate of the mutual information, and this resulting estimator
of mutual information will be asymptotically independent of the choice
of number of classes $K$.




\end{document}





